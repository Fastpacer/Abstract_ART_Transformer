{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOh2wSCrc51FrUEMgolju7K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fastpacer/Abstract_ART_Transformer/blob/main/Machine_Learning_Internship_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NUtNEr0C3lXY",
        "outputId": "4bd2abde-ec04-4be4-c947-cbb3c56b7edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.44.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.6.9)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.31.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio) (0.38.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Using device: cpu\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://89cd63236161877179.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://89cd63236161877179.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating frames: 100%|██████████| 90/90 [02:14<00:00,  1.50s/it]\n",
            "Writing video: 100%|██████████| 90/90 [00:00<00:00, 720.80it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/components/video.py:327: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n",
            "Generating frames:  36%|███▌      | 65/180 [01:33<03:05,  1.61s/it]"
          ]
        }
      ],
      "source": [
        "# Install required dependencies\n",
        "!pip install torch torchvision opencv-python pillow numpy tqdm gradio\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "from google.colab import files\n",
        "from IPython.display import HTML, display\n",
        "from pathlib import Path\n",
        "\n",
        "# First Cell: Model Implementation\n",
        "class StyleEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StyleEncoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "class TransformationGenerator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TransformationGenerator, self).__init__()\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "        self.conv1 = nn.Conv2d(3 + 128, 64, kernel_size=7, stride=1, padding=3)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 3, kernel_size=7, stride=1, padding=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, image, style):\n",
        "        batch_size, _, h, w = image.shape\n",
        "        style = style.view(batch_size, -1, 1, 1).repeat(1, 1, h, w)\n",
        "        x = torch.cat([image, style], dim=1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        return self.tanh(self.conv3(x))\n",
        "\n",
        "class AbstractArtTransformer:\n",
        "    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        self.device = device\n",
        "        self.style_encoder = StyleEncoder().to(device)\n",
        "        self.generator = TransformationGenerator().to(device)\n",
        "        print(f\"Using device: {device}\")\n",
        "\n",
        "    def apply_brushstroke_effect(self, image):\n",
        "        if isinstance(image, torch.Tensor):\n",
        "            image = image.cpu().numpy().transpose(1, 2, 0)\n",
        "        brushstroke = cv2.bilateralFilter(image, 9, 75, 75)\n",
        "        return torch.tensor(brushstroke.transpose(2, 0, 1)).to(self.device)\n",
        "\n",
        "    def apply_color_distortion(self, image, intensity=0.5):\n",
        "        jitter = transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)\n",
        "        return jitter(image)\n",
        "\n",
        "    def create_transformation_sequence(self, image, style_prompt, num_frames=30):\n",
        "        frames = []\n",
        "        style_vector = torch.randn(1, 128).to(self.device)\n",
        "\n",
        "        for i in tqdm(range(num_frames), desc=\"Generating frames\"):\n",
        "            abstraction_level = i / num_frames\n",
        "            distorted_image = self.apply_color_distortion(image, intensity=abstraction_level)\n",
        "            brushstroke_image = self.apply_brushstroke_effect(distorted_image)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                transformed_frame = self.generator(brushstroke_image.unsqueeze(0), style_vector)\n",
        "\n",
        "            frames.append(transformed_frame.squeeze(0))\n",
        "\n",
        "        return frames\n",
        "\n",
        "    def create_video(self, frames, output_path, fps=24):\n",
        "        frames = [frame.cpu().numpy().transpose(1, 2, 0) for frame in frames]\n",
        "        frames = [(frame * 255).astype(np.uint8) for frame in frames]\n",
        "        height, width, _ = frames[0].shape\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        for frame in tqdm(frames, desc=\"Writing video\"):\n",
        "            video_writer.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        video_writer.release()\n",
        "\n",
        "# Second Cell: Gradio Interface Implementation\n",
        "class ArtTransformerApp:\n",
        "    def __init__(self):\n",
        "        self.transformer = AbstractArtTransformer()\n",
        "        self.available_styles = [\"Cubism\", \"Surrealism\", \"Impressionism\", \"Abstract Expressionism\",\n",
        "                                \"Pop Art\", \"Minimalism\", \"Art Nouveau\", \"Pointillism\"]\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    def process_image(self, input_image, style, abstraction_level, frame_count):\n",
        "        if isinstance(input_image, str):\n",
        "            input_image = Image.open(input_image)\n",
        "\n",
        "        image_tensor = self.transform(input_image).to(self.transformer.device)\n",
        "\n",
        "        frames = self.transformer.create_transformation_sequence(\n",
        "            image_tensor,\n",
        "            style,\n",
        "            num_frames=frame_count\n",
        "        )\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:\n",
        "            output_path = tmp_file.name\n",
        "\n",
        "        self.transformer.create_video(frames, output_path)\n",
        "\n",
        "        return output_path\n",
        "\n",
        "# Third Cell: Create and Launch Gradio Interface\n",
        "def create_gradio_interface():\n",
        "    app = ArtTransformerApp()\n",
        "\n",
        "    with gr.Blocks(title=\"Abstract Art Style Transformer\") as interface:\n",
        "        gr.Markdown(\"# Abstract Art Style Transformer\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                input_image = gr.Image(type=\"pil\", label=\"Input Image\")\n",
        "                style = gr.Dropdown(\n",
        "                    choices=app.available_styles,\n",
        "                    label=\"Art Style\",\n",
        "                    value=\"Cubism\"\n",
        "                )\n",
        "                abstraction_level = gr.Slider(\n",
        "                    minimum=0.1,\n",
        "                    maximum=1.0,\n",
        "                    value=0.5,\n",
        "                    step=0.1,\n",
        "                    label=\"Abstraction Level\"\n",
        "                )\n",
        "                frame_count = gr.Slider(\n",
        "                    minimum=30,\n",
        "                    maximum=300,\n",
        "                    value=90,\n",
        "                    step=30,\n",
        "                    label=\"Video Length (frames)\"\n",
        "                )\n",
        "                generate_btn = gr.Button(\"Generate Abstract Art Video\")\n",
        "\n",
        "            with gr.Column():\n",
        "                output_video = gr.Video(label=\"Generated Video\")\n",
        "\n",
        "        generate_btn.click(\n",
        "            fn=app.process_image,\n",
        "            inputs=[input_image, style, abstraction_level, frame_count],\n",
        "            outputs=output_video\n",
        "        )\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Fourth Cell: Main Execution\n",
        "def main():\n",
        "    interface = create_gradio_interface()\n",
        "    interface.launch(debug=True, share=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# Fifth Cell: Download Helper Function\n",
        "def download_video(file_path):\n",
        "    try:\n",
        "        files.download(file_path)\n",
        "    except:\n",
        "        print(f\"Video saved at: {file_path}\")"
      ]
    }
  ]
}