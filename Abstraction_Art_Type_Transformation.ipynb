{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD9Nw6bOY7a5yttvaO1qp4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fastpacer/Abstract_ART_Transformer/blob/main/Abstraction_Art_Type_Transformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vxhEJ3ehcdT_",
        "outputId": "1505abcb-4b03-4c6c-aea3-868f76bd971b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "my_project_art_transform\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.44.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.6.9)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.31.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio) (0.38.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a1d29bbc61bf87c292.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a1d29bbc61bf87c292.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Free setup for Google Colab\n",
        "# No paid resources or GPU required\n",
        "\n",
        "!pip install opencv-python-headless pillow numpy gradio\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "\n",
        "def create_simple_effect(image):\n",
        "    # Convert to numpy array if it's a PIL image\n",
        "    if isinstance(image, Image.Image):\n",
        "        image = np.array(image)\n",
        "\n",
        "    # Create some simple artistic effects\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    colored_edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Create a simple artistic effect\n",
        "    art_effect = cv2.addWeighted(image, 0.7, colored_edges, 0.3, 0)\n",
        "\n",
        "    return Image.fromarray(art_effect)\n",
        "\n",
        "def test_pipeline(input_img):\n",
        "    try:\n",
        "        # Apply effect\n",
        "        result = create_simple_effect(input_img)\n",
        "        return result, \"Success! Basic image processing is working.\"\n",
        "    except Exception as e:\n",
        "        return None, f\"Error: {str(e)}\"\n",
        "\n",
        "# Create a simple Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=test_pipeline,\n",
        "    inputs=gr.Image(),\n",
        "    outputs=[gr.Image(), gr.Textbox()],\n",
        "    title=\"Free Art Effect Test\",\n",
        "    description=\"Upload an image to test basic artistic effects\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "CYzyRsfkct43",
        "outputId": "f8f9c778-0ffe-4064-b15f-00be53eb886a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://3cb5b7a2846eb16b5e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3cb5b7a2846eb16b5e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "\n",
        "class ArtisticEffects:\n",
        "    @staticmethod\n",
        "    def apply_brushstroke(image):\n",
        "        # Convert PIL to cv2 if necessary\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Create brush stroke effect\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        edges = cv2.dilate(edges, None)\n",
        "\n",
        "        # Create color quantization for painterly effect\n",
        "        Z = image.reshape((-1,3))\n",
        "        Z = np.float32(Z)\n",
        "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "        K = 8\n",
        "        _, labels, centers = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "        centers = np.uint8(centers)\n",
        "        res = centers[labels.flatten()]\n",
        "        quantized = res.reshape((image.shape))\n",
        "\n",
        "        # Combine edges with quantized image\n",
        "        result = cv2.addWeighted(quantized, 0.7, cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 0.3, 0)\n",
        "        return Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_color_palette(image, style=\"vivid\"):\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        palettes = {\n",
        "            \"vivid\": [(255,0,0), (0,255,0), (0,0,255), (255,255,0)],\n",
        "            \"pastel\": [(255,182,193), (176,224,230), (255,218,185), (221,160,221)],\n",
        "            \"monochrome\": [(0,0,0), (128,128,128), (255,255,255)]\n",
        "        }\n",
        "\n",
        "        selected_palette = palettes.get(style, palettes[\"vivid\"])\n",
        "\n",
        "        Z = image.reshape((-1,3))\n",
        "        Z = np.float32(Z)\n",
        "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "        K = len(selected_palette)\n",
        "        _, labels, _ = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "        # Replace colors with palette colors\n",
        "        palette_centers = np.uint8(selected_palette)\n",
        "        res = palette_centers[labels.flatten()]\n",
        "        result = res.reshape((image.shape))\n",
        "\n",
        "        return Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "def process_image(image, style_choice):\n",
        "    effects = ArtisticEffects()\n",
        "\n",
        "    # Apply brush stroke effect\n",
        "    brushstroke_img = effects.apply_brushstroke(image)\n",
        "\n",
        "    # Apply color palette based on style\n",
        "    final_img = effects.apply_color_palette(brushstroke_img, style_choice)\n",
        "\n",
        "    return final_img\n",
        "\n",
        "# Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=process_image,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\"),\n",
        "        gr.Radio([\"vivid\", \"pastel\", \"monochrome\"], label=\"Color Style\")\n",
        "    ],\n",
        "    outputs=gr.Image(type=\"pil\"),\n",
        "    title=\"Abstract Art Style Transformer - Day 1\",\n",
        "    description=\"Apply artistic effects to your image\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import io\n",
        "import base64\n",
        "\n",
        "class ArtisticVideoTransformer:\n",
        "    def __init__(self):\n",
        "        self.styles = {\n",
        "            \"cubism\": self._apply_cubism,\n",
        "            \"impressionism\": self._apply_impressionism,\n",
        "            \"surrealism\": self._apply_surrealism\n",
        "        }\n",
        "\n",
        "    def _apply_cubism(self, image, intensity=0.5):\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Create geometric shapes effect\n",
        "        triangles = self._create_triangulation(image)\n",
        "        edges = cv2.Canny(image, 100, 200)\n",
        "\n",
        "        # Combine effects\n",
        "        result = cv2.addWeighted(triangles, intensity, image, 1-intensity, 0)\n",
        "        result = cv2.addWeighted(result, 0.8, cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 0.2, 0)\n",
        "\n",
        "        return cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    def _apply_impressionism(self, image, intensity=0.5):\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Create brushstroke effect\n",
        "        blurred = cv2.GaussianBlur(image, (21, 21), 0)\n",
        "        color_boost = cv2.addWeighted(image, 1.5, blurred, -0.5, 0)\n",
        "\n",
        "        # Add texture\n",
        "        noise = np.random.normal(0, 50, image.shape).astype(np.uint8)\n",
        "        textured = cv2.add(color_boost, noise)\n",
        "\n",
        "        return cv2.cvtColor(textured, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    def _apply_surrealism(self, image, intensity=0.5):\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Create dream-like effect\n",
        "        hue_shifted = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        hue_shifted[:,:,0] = (hue_shifted[:,:,0] + 50) % 180\n",
        "        surreal = cv2.cvtColor(hue_shifted, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "        # Add wave distortion\n",
        "        rows, cols = image.shape[:2]\n",
        "        wave_matrix = np.zeros((rows,cols,2), np.float32)\n",
        "        for i in range(rows):\n",
        "            for j in range(cols):\n",
        "                wave_matrix[i,j] = [j, i + 25.0 * np.sin(j/30.0)]\n",
        "        distorted = cv2.remap(surreal, wave_matrix, None, cv2.INTER_LINEAR)\n",
        "\n",
        "        return cv2.cvtColor(distorted, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    def _create_triangulation(self, image):\n",
        "        height, width = image.shape[:2]\n",
        "        subdiv = cv2.Subdiv2D((0, 0, width, height))\n",
        "\n",
        "        # Add points for triangulation\n",
        "        points = np.array([(x, y) for x in range(0, width, 50)\n",
        "                                  for y in range(0, height, 50)], dtype=np.float32)\n",
        "        for point in points:\n",
        "            subdiv.insert(tuple(map(float, point)))\n",
        "\n",
        "        triangles = subdiv.getTriangleList()\n",
        "        triangles = np.array(triangles, dtype=np.int32)\n",
        "\n",
        "        img_triangles = np.zeros_like(image)\n",
        "        for t in triangles:\n",
        "            pt1 = (t[0], t[1])\n",
        "            pt2 = (t[2], t[3])\n",
        "            pt3 = (t[4], t[5])\n",
        "\n",
        "            color = image[t[1], t[0]].tolist()\n",
        "            cv2.fillPoly(img_triangles, [np.array([pt1, pt2, pt3])], color)\n",
        "\n",
        "        return img_triangles\n",
        "\n",
        "    def generate_frames(self, image, style, num_frames=10):\n",
        "        frames = []\n",
        "        for i in range(num_frames):\n",
        "            intensity = i / (num_frames - 1)\n",
        "            frame = self.styles[style](image, intensity)\n",
        "            frames.append(Image.fromarray(frame))\n",
        "        return frames\n",
        "\n",
        "def process_to_video(image, style):\n",
        "    transformer = ArtisticVideoTransformer()\n",
        "    frames = transformer.generate_frames(image, style)\n",
        "\n",
        "    # Convert frames to a displayable format\n",
        "    output_frames = []\n",
        "    for frame in frames:\n",
        "        output_frames.append(frame)\n",
        "\n",
        "    return output_frames\n",
        "\n",
        "# Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=process_to_video,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\"),\n",
        "        gr.Radio([\"cubism\", \"impressionism\", \"surrealism\"], label=\"Art Style\")\n",
        "    ],\n",
        "    outputs=gr.Gallery(),\n",
        "    title=\"Abstract Art Video Transformer \",\n",
        "    description=\"Transform your image into different art styles with frame progression\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "fCXoWOdMeUr-",
        "outputId": "c6e5ca7e-820a-49e2-edce-f9b214d0544d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://242ed0b25384f52063.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://242ed0b25384f52063.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "class VideoArtTransformer:\n",
        "    def __init__(self):\n",
        "        self.styles = {\n",
        "            \"cubism\": self._apply_cubism,\n",
        "            \"impressionism\": self._apply_impressionism,\n",
        "            \"surrealism\": self._apply_surrealism\n",
        "        }\n",
        "\n",
        "    def _apply_cubism(self, image, intensity):\n",
        "        # Enhanced cubism effect\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Create polygonal shapes\n",
        "        mask = np.zeros_like(image)\n",
        "        for contour in contours:\n",
        "            if cv2.contourArea(contour) > 100:\n",
        "                epsilon = 0.02 * cv2.arcLength(contour, True) * intensity\n",
        "                approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "                cv2.fillPoly(mask, [approx], (np.random.randint(0,255), np.random.randint(0,255), np.random.randint(0,255)))\n",
        "\n",
        "        return cv2.addWeighted(image, 1-intensity, mask, intensity, 0)\n",
        "\n",
        "    def _apply_impressionism(self, image, intensity):\n",
        "        # Enhanced impressionism effect\n",
        "        size = int(10 * intensity) * 2 + 1\n",
        "        blurred = cv2.GaussianBlur(image, (size, size), 0)\n",
        "\n",
        "        # Color variation\n",
        "        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
        "        hsv[:,:,1] = hsv[:,:,1] * (1 + intensity/2)  # Increase saturation\n",
        "        colored = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "        # Add brushstroke texture\n",
        "        kernel = np.ones((5,5),np.float32)/25\n",
        "        texture = cv2.filter2D(colored,-1,kernel)\n",
        "\n",
        "        return cv2.addWeighted(image, 1-intensity, texture, intensity, 0)\n",
        "\n",
        "    def _apply_surrealism(self, image, intensity):\n",
        "        # Enhanced surrealism effect\n",
        "        rows, cols = image.shape[:2]\n",
        "\n",
        "        # Create dream-like distortion\n",
        "        wave_length = int(30 * (1-intensity) + 10)\n",
        "        amplitude = int(40 * intensity)\n",
        "\n",
        "        map_x = np.zeros((rows,cols), np.float32)\n",
        "        map_y = np.zeros((rows,cols), np.float32)\n",
        "\n",
        "        for i in range(rows):\n",
        "            for j in range(cols):\n",
        "                map_x[i,j] = j + amplitude * np.sin(i/wave_length)\n",
        "                map_y[i,j] = i + amplitude * np.cos(j/wave_length)\n",
        "\n",
        "        distorted = cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR)\n",
        "\n",
        "        # Color manipulation\n",
        "        hsv = cv2.cvtColor(distorted, cv2.COLOR_BGR2HSV)\n",
        "        hsv[:,:,0] = (hsv[:,:,0] + int(90 * intensity)) % 180\n",
        "        surreal = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "        return surreal\n",
        "\n",
        "    def generate_video(self, image, style, duration=5):\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Video settings\n",
        "        fps = 30\n",
        "        frame_count = duration * fps\n",
        "        height, width = image.shape[:2]\n",
        "\n",
        "        # Create temporary file for video\n",
        "        temp_output = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False)\n",
        "        output_path = temp_output.name\n",
        "\n",
        "        # Initialize video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        style_func = self.styles[style]\n",
        "\n",
        "        for frame_num in range(frame_count):\n",
        "            intensity = frame_num / frame_count\n",
        "            frame = style_func(image.copy(), intensity)\n",
        "            out.write(frame)\n",
        "\n",
        "        out.release()\n",
        "\n",
        "        return output_path\n",
        "\n",
        "def process_video(image, style, duration=5):\n",
        "    transformer = VideoArtTransformer()\n",
        "    video_path = transformer.generate_video(image, style, duration)\n",
        "    return video_path\n",
        "\n",
        "# Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=process_video,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Input Image\"),\n",
        "        gr.Radio([\"cubism\", \"impressionism\", \"surrealism\"], label=\"Art Style\"),\n",
        "        gr.Slider(minimum=1, maximum=10, value=5, step=1, label=\"Duration (seconds)\")\n",
        "    ],\n",
        "    outputs=gr.Video(),\n",
        "    title=\"Abstract Art Video Transformer\",\n",
        "    description=\"Transform your image into an artistic video\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "G8TqRxWzeUv6",
        "outputId": "69cf68fd-6e14-4a9e-82c6-fc0ad5d9f8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://abecf1d7c14f74aab8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://abecf1d7c14f74aab8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gradio deploy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYzBNWSkrD87",
        "outputId": "9d89abc3-699b-44f0-ee41-72db4f7df45d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Need \u001b[32m'write'\u001b[0m access token to create a Spaces repo.\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _blend_styles(self, image, intensity, styles):\n",
        "    blended_image = image.copy()\n",
        "    num_styles = len(styles)\n",
        "    for i, style in enumerate(styles):\n",
        "        style_func = self.styles[style]\n",
        "        blend_intensity = (intensity * (i+1)) / num_styles\n",
        "        blended_image = style_func(blended_image, blend_intensity)\n",
        "    return blended_image\n",
        "\n",
        "def generate_video(self, image, styles, duration=5):\n",
        "    if isinstance(image, Image.Image):\n",
        "        image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    fps = 30\n",
        "    frame_count = duration * fps\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    temp_output = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False)\n",
        "    output_path = temp_output.name\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for frame_num in range(frame_count):\n",
        "        intensity = frame_num / frame_count\n",
        "        frame = self._blend_styles(image.copy(), intensity, styles)\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "    return output_path\n"
      ],
      "metadata": {
        "id": "QZxEf2YheUz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_custom_video(self, image, styles, params, duration=5):\n",
        "    fps = 30\n",
        "    frame_count = duration * fps\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    temp_output = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False)\n",
        "    output_path = temp_output.name\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for frame_num in range(frame_count):\n",
        "        intensity = frame_num / frame_count\n",
        "        custom_params = {key: params[key] * intensity for key in params}\n",
        "        frame = self._apply_custom_style(image.copy(), intensity, styles, custom_params)\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "    return output_path"
      ],
      "metadata": {
        "id": "BJV_8BbOeU3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def _generate_frame(self, args):\n",
        "    image, style, intensity = args\n",
        "    style_func = self.styles[style]\n",
        "    return style_func(image, intensity)\n",
        "\n",
        "def generate_video_parallel(self, image, styles, duration=5):\n",
        "    fps = 30\n",
        "    frame_count = duration * fps\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    temp_output = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False)\n",
        "    output_path = temp_output.name\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    with Pool() as pool:\n",
        "        frames = pool.map(self._generate_frame, [(image, styles, frame_num / frame_count) for frame_num in range(frame_count)])\n",
        "\n",
        "    for frame in frames:\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "    return output_path"
      ],
      "metadata": {
        "id": "lxeBq54ieU6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
        "!pip install -r pytorch-CycleGAN-and-pix2pix/requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc_RwLH8LdqN",
        "outputId": "e3a71296-7dda-41b9-8e71-a20da658108e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 2516, done.\u001b[K\n",
            "remote: Total 2516 (delta 0), reused 0 (delta 0), pack-reused 2516 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2516/2516), 8.20 MiB | 17.03 MiB/s, done.\n",
            "Resolving deltas: 100% (1575/1575), done.\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 1)) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from -r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 2)) (0.19.1+cu121)\n",
            "Collecting dominate>=2.4.0 (from -r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 3))\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting visdom>=0.1.8.8 (from -r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4))\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb (from -r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5))\n",
            "  Downloading wandb-0.18.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 1)) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 2)) (10.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (6.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (1.16.0)\n",
            "Collecting jsonpatch (from visdom>=0.1.8.8->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5)) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5)) (6.0.2)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5))\n",
            "  Downloading sentry_sdk-2.15.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5)) (71.0.4)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visdom>=0.1.8.8->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visdom>=0.1.8.8->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visdom>=0.1.8.8->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visdom>=0.1.8.8->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 1)) (2.1.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch->visdom>=0.1.8.8->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4))\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 1)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Downloading wandb-0.18.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.15.0-py2.py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.0/311.0 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408195 sha256=8198bc5ee2af7e02baf7a616d119a061c451a799284a54a07224d5377d287661\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n",
            "Successfully built visdom\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, jsonpointer, dominate, docker-pycreds, jsonpatch, gitdb, visdom, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 dominate-2.9.1 gitdb-4.0.11 gitpython-3.1.43 jsonpatch-1.33 jsonpointer-3.0.0 sentry-sdk-2.15.0 setproctitle-1.3.3 smmap-5.0.1 visdom-0.2.4 wandb-0.18.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow-hub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-8Y0s0ih4Lo",
        "outputId": "26e3d0da-7539-4383-911b-a295e1aa7d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (2.17.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "QfJAY12YLF2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tempfile\n",
        "from PIL import Image\n",
        "\n",
        "class VideoArtTransformer:\n",
        "    def __init__(self, use_gan=False):\n",
        "        self.use_gan = use_gan\n",
        "        if use_gan:\n",
        "            # Load the model from TensorFlow Hub (change this if using a different model)\n",
        "            self.gan_model = hub.load(\"https://tfhub.dev/google/progan-128/1\")\n",
        "        else:\n",
        "            self.gan_model = None\n",
        "\n",
        "    def _apply_gan_style(self, image):\n",
        "        if self.use_gan:\n",
        "            # Preprocess image if needed\n",
        "            image_resized = tf.image.resize(image, [128, 128])\n",
        "            image_resized = (image_resized - 127.5) / 127.5  # Normalize between [-1, 1]\n",
        "            image_resized = tf.expand_dims(image_resized, 0)  # Add batch dimension\n",
        "\n",
        "            # Apply the GAN model to generate the transformed image\n",
        "            generated_image = self.gan_model(image_resized)\n",
        "            generated_image = (generated_image[0] * 127.5 + 127.5).numpy().astype(np.uint8)  # Denormalize\n",
        "\n",
        "            return generated_image\n",
        "\n",
        "        return image\n",
        "\n",
        "    def generate_video_with_gan(self, image, style, duration=5):\n",
        "        # Convert PIL image to numpy array (if applicable)\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = np.array(image)\n",
        "\n",
        "        fps = 30\n",
        "        frame_count = duration * fps\n",
        "        height, width = image.shape[:2]\n",
        "\n",
        "        # Create temporary file for video output\n",
        "        temp_output = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False)\n",
        "        output_path = temp_output.name\n",
        "\n",
        "        # Initialize video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        for frame_num in range(frame_count):\n",
        "            # Apply GAN style transformation to each frame\n",
        "            frame = self._apply_gan_style(image.copy())\n",
        "            out.write(frame)\n",
        "\n",
        "        out.release()\n",
        "        return output_path\n"
      ],
      "metadata": {
        "id": "NYbAFsBwLF6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_6gFfdBLGAK",
        "outputId": "6c64a6a1-b067-4751-bae6-af964db20614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio)\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.0 ffmpy-0.4.0 gradio-4.44.1 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.12 ruff-0.6.9 semantic-version-2.10.0 starlette-0.38.6 tomlkit-0.12.0 uvicorn-0.31.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_video_with_gan(self, image, style, duration=5):\n",
        "    # Convert PIL image to numpy array (if applicable)\n",
        "    if isinstance(image, Image.Image):\n",
        "        image = np.array(image)\n",
        "\n",
        "    fps = 30\n",
        "    frame_count = duration * fps\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Create temporary file for video output\n",
        "    temp_output = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False)\n",
        "    output_path = temp_output.name\n",
        "\n",
        "    # Initialize video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for frame_num in range(frame_count):\n",
        "        try:\n",
        "            # Apply GAN style transformation to each frame\n",
        "            frame = self._apply_gan_style(image.copy())\n",
        "            frame = cv2.resize(frame, (width, height))  # Ensure consistent frame size\n",
        "\n",
        "            # Save frame for debugging purposes\n",
        "            cv2.imwrite(f\"frame_{frame_num}.png\", frame)  # Debug: save frame\n",
        "\n",
        "            out.write(frame)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error at frame {frame_num}: {e}\")  # Print error for debugging\n",
        "\n",
        "    out.release()\n",
        "    return output_path\n"
      ],
      "metadata": {
        "id": "QYvKvPG_lPnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Define a function for Gradio to process video generation\n",
        "def process_video_with_gan(image, duration=5):\n",
        "    transformer = VideoArtTransformer(use_gan=True)\n",
        "    video_path = transformer.generate_video_with_gan(image, style=\"gan\", duration=duration)\n",
        "    return video_path\n",
        "\n"
      ],
      "metadata": {
        "id": "sNSmLkmElPq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=process_video_with_gan,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Input Image\"),  # Image input\n",
        "        gr.Slider(minimum=1, maximum=10, value=5, step=1, label=\"Duration (seconds)\")  # Slider for duration\n",
        "    ],\n",
        "    outputs=gr.Video(label=\"Generated Video\"),  # Video output\n",
        "    title=\"Abstract Art Video Transformer\",\n",
        "    description=\"Transform an image into an abstract art video using a GAN.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "5AfH-eXvlPw7",
        "outputId": "4e9f93db-d1d0-4ca0-e1e7-ece9ee684337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://f222f9e0c524fb2bdd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f222f9e0c524fb2bdd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ffbg0vxHlP0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tT69G0xmLGC2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}